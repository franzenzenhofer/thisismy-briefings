{
  "selectedFiles": [],
  "selectedURLs": [],
  "selectedNotes": [],
  "selectedSpecials": [
    [
      "page:1732198150881",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/.gpt_action_getting_started"
      }
    ],
    [
      "page:1732198160957",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://platform.openai.com/docs/actions/introduction"
      }
    ],
    [
      "page:1732198169327",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://platform.openai.com/docs/actions/actions-library"
      }
    ],
    [
      "page:1732198204002",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://platform.openai.com/docs/actions/getting-started"
      }
    ],
    [
      "page:1732198467785",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://help.openai.com/en/articles/8554397-creating-a-gpt"
      }
    ],
    [
      "page:1732198470829",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://help.openai.com/en/articles/8843948-knowledge-in-gpts"
      }
    ],
    [
      "page:1732198484906",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts"
      }
    ],
    [
      "page:1732198492433",
      {
        "icon": "üì∞",
        "name": "Current Page Content from https://help.openai.com/en/articles/9358033-key-guidelines-for-writing-instructions-for-custom-gpts"
      }
    ]
  ],
  "outputContents": [
    [
      "page:1732198150881",
      "Fetched content from https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/.gpt_action_getting_started on 2024-11-21 14:09:10\n\nCookbook\nTopics\nAbout\nAPI Docs\nContribute\nToggle theme\nSearch...\n‚åò\nK\nGPT Actions library - getting started\nAaron Wilkowitz\nJul 9, 2024\nOpen in Github\nIntroduction\n\nThis page provides an instruction & guide for developers building a GPT Action for a specific application. Before you proceed, make sure to first familiarize yourself with the following information:\n\nIntroduction to GPT Actions\nIntroduction to GPT Actions Library\nExample of Buliding a GPT Action from Scratch\n\nThis particular GPT Action provides an overview of how to connect to a Weather.gov weather forecast. This Action takes a user‚Äôs question about a location, converts the lat-long into a weather forecast office (WFO), x, and y coordinates, then converts those 3 values into a weather forecast.\n\nNote: When setting up the GPT Action, for authentication, leave it with \"None\". This is a public API and does not require any Authentication\n\nValue + Example Business Use Cases\n\nValue: Users can now leverage ChatGPT's natural language capability to forecast the weather\n\nExample Use Cases:\n\nUsers can plan out their day based on weather patterns\nUsers can quickly visualize (including graphs) what the weather is forecasted to look like\nApplication Information\nApplication Key Links\n\nCheck out these links from the application before you get started:\n\nApplication Website: https://www.weather.gov/\nApplication API Documentation: https://www.weather.gov/documentation/services-web-api\nChatGPT Steps\nCustom GPT Instructions\n\nOnce you've created a Custom GPT, copy the text below in the Instructions panel. Have questions? Check out Getting Started Example to see how this step works in more detail.\n\n**Context**: A user needs information related to a weather forecast of a specific location.\n\n**Instructions**:\n1. The user will provide a lat-long point or a general location or landmark (e.g. New York City, the White House). If the user does not provide one, ask for the relevant location\n2. If the user provides a general location or landmark, convert that into a lat-long coordinate. If required, browse the web to look up the lat-long point. \n3. Run the \"getPointData\" API action and retrieve back the gridId, gridX, and gridY parameters.\n4. Apply those variables as the office, gridX, and gridY variables in the \"getGridpointForecast\" API action to retrieve back a forecast\n5. Use that forecast to answer the user's question \n\n**Additional Notes**: \n- Assume the user uses US weather units (e.g. Farenheit) unless otherwise specified\n- If the user says \"Let's get started\" or \"What do I do?\", explain the purpose of this Custom GPT\nOpenAPI Schema\n\nOnce you've created a Custom GPT, copy the text below in the Actions panel. Have questions? Check out Getting Started Example to see how this step works in more detail.\n\nopenapi: 3.1.0\ninfo:\n  title: NWS Weather API\n  description: Access to weather data including forecasts, alerts, and observations.\n  version: 1.0.0\nservers:\n  - url: https://api.weather.gov\n    description: Main API Server\npaths:\n  /points/{latitude},{longitude}:\n    get:\n      operationId: getPointData\n      summary: Get forecast grid endpoints for a specific location\n      parameters:\n        - name: latitude\n          in: path\n          required: true\n          schema:\n            type: number\n            format: float\n          description: Latitude of the point\n        - name: longitude\n          in: path\n          required: true\n          schema:\n            type: number\n            format: float\n          description: Longitude of the point\n      responses:\n        '200':\n          description: Successfully retrieved grid endpoints\n          content:\n            application/json:\n              schema:\n                type: object\n                properties:\n                  properties:\n                    type: object\n                    properties:\n                      forecast:\n                        type: string\n                        format: uri\n                      forecastHourly:\n                        type: string\n                        format: uri\n                      forecastGridData:\n                        type: string\n                        format: uri\n\n  /gridpoints/{office}/{gridX},{gridY}/forecast:\n    get:\n      operationId: getGridpointForecast\n      summary: Get forecast for a given grid point\n      parameters:\n        - name: office\n          in: path\n          required: true\n          schema:\n            type: string\n          description: Weather Forecast Office ID\n        - name: gridX\n          in: path\n          required: true\n          schema:\n            type: integer\n          description: X coordinate of the grid\n        - name: gridY\n          in: path\n          required: true\n          schema:\n            type: integer\n          description: Y coordinate of the grid\n      responses:\n        '200':\n          description: Successfully retrieved gridpoint forecast\n          content:\n            application/json:\n              schema:\n                type: object\n                properties:\n                  properties:\n                    type: object\n                    properties:\n                      periods:\n                        type: array\n                        items:\n                          type: object\n                          properties:\n                            number:\n                              type: integer\n                            name:\n                              type: string\n                            startTime:\n                              type: string\n                              format: date-time\n                            endTime:\n                              type: string\n                              format: date-time\n                            temperature:\n                              type: integer\n                            temperatureUnit:\n                              type: string\n                            windSpeed:\n                              type: string\n                            windDirection:\n                              type: string\n                            icon:\n                              type: string\n                              format: uri\n                            shortForecast:\n                              type: string\n                            detailedForecast:\n                              type: string\nFAQ & Troubleshooting\n\nAre there integrations that you‚Äôd like us to prioritize? Are there errors in our integrations? File a PR or issue in our github, and we‚Äôll take a look.\n\nEnd of content from https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/.gpt_action_getting_started"
    ],
    [
      "page:1732198160957",
      "Fetched content from https://platform.openai.com/docs/actions/introduction on 2024-11-21 14:09:20\n\nF\nf19n.com\n/\nNeverendingjoke\nPlayground\nDashboard\nDocs\nAPI\nSearch\n‚åò\nK\nGET STARTED\nOverview\nQuickstart\nModels\nChangelog\nTerms and policies\nCAPABILITIES\nText generation\nImage generation\nVision\nAudio generation\nText to speech\nSpeech to text\nEmbeddings\nModeration\nReasoning\nGUIDES\nFunction calling\nStructured Outputs\nPredicted Outputs\nEvaluations\nFine-tuning\nDistillation\nRealtime API\nBatch API\nASSISTANTS\nOverview\nQuickstart\nDeep dive\nTools\nWhat's new?\nMigration guide\nCHATGPT\nActions\nIntroduction\nGetting started\nActions library\nAuthentication\nProduction\nData retrieval\nSending files\nPolicies\nRelease notes\nBEST PRACTICES\nPrompt engineering\nProduction best practices\nSafety best practices\nPrompt Caching\nModel selection\nLatency optimization\nAccuracy optimization\nAdvanced usage\nRESOURCES\nLibraries\nPrompt examples\nRate limits\nPrompt generation\nError codes\nDeprecations\nCookbook\nForum\nHelp\nGPT Actions\nCustomize ChatGPT with GPT Actions and API integrations.\n\nGPT Actions are stored in Custom GPTs, which enable users to customize ChatGPT for specific use cases by providing instructions, attaching documents as knowledge, and connecting to 3rd party services.\n\nGPT Actions empower ChatGPT users to interact with external applications via RESTful APIs calls outside of ChatGPT simply by using natural language. They convert natural language text into the json schema required for an API call. GPT Actions are usually either used to do data retrieval to ChatGPT (e.g. query a Data Warehouse) or take action in another application (e.g. file a JIRA ticket).\n\nHow GPT Actions work\n\nAt their core, GPT Actions leverage Function Calling to execute API calls.\n\nSimilar to ChatGPT's Data Analysis capability (which generates Python code and then executes it), they leverage Function Calling to (1) decide which API call is relevant to the user's question and (2) generate the json input necessary for the API call. Then finally, the GPT Action executes the API call using that json input.\n\nDevelopers can even specify the authentication mechanism of an action, and the Custom GPT will execute the API call using the third party app‚Äôs authentication. GPT Actions obfuscates the complexity of the API call to the end user: they simply ask a question in natural language, and ChatGPT provides the output in natural language as well.\n\nThe Power of GPT Actions\n\nAPIs allow for interoperability to enable your organization to access other applications. However, enabling users to access the right information from 3rd-party APIs can require significant overhead from developers.\n\nGPT Actions provide a viable alternative: developers can now simply describe the schema of an API call, configure authentication, and add in some instructions to the GPT, and ChatGPT provides the bridge between the user's natural language questions and the API layer.\n\nSimplified example\n\nThe getting started guide walks through an example using two API calls from weather.gov to generate a forecast:\n\n/points/{latitude},{longitude} inputs lat-long coordinates and outputs forecast office (wfo) and x-y coordinates\n/gridpoints/{office}/{gridX},{gridY}/forecast inputs wfo,x,y coordinates and outputs a forecast\n\nOnce a developer has encoded the json schema required to populate both of those API calls in a GPT Action, a user can simply ask \"What I should pack on a trip to Washington DC this weekend?\" The GPT Action will then figure out the lat-long of that location, execute both API calls in order, and respond with a packing list based on the weekend forecast it receives back.\n\nIn this example, GPT Actions will supply api.weather.gov with two API inputs:\n\n/points API call:\n\n1\n2\n3\n4\n\n{\n    \"latitude\": 38.9072,\n    \"longitude\": -77.0369,\n}\n\n/forecast API call:\n\n1\n2\n3\n4\n5\n\n{\n    \"wfo\": \"LWX\",\n    \"x\": 97,\n    \"y\": 71,\n}\nGet started on building\n\nCheck out the getting started guide for a deeper dive on this weather example and our actions library for pre-built example GPT Actions of the most common 3rd party apps.\n\nAdditional information\nFamiliarize yourself with our GPT policies\nExplore the differences between GPTs and Assistants\nCheck out the GPT data privacy FAQ's\nFind answers to common GPT questions\nWas this page useful?\n\nEnd of content from https://platform.openai.com/docs/actions/introduction"
    ],
    [
      "page:1732198169327",
      "Fetched content from https://platform.openai.com/docs/actions/actions-library on 2024-11-21 14:09:29\n\nF\nf19n.com\n/\nNeverendingjoke\nPlayground\nDashboard\nDocs\nAPI\nSearch\n‚åò\nK\nGET STARTED\nOverview\nQuickstart\nModels\nChangelog\nTerms and policies\nCAPABILITIES\nText generation\nImage generation\nVision\nAudio generation\nText to speech\nSpeech to text\nEmbeddings\nModeration\nReasoning\nGUIDES\nFunction calling\nStructured Outputs\nPredicted Outputs\nEvaluations\nFine-tuning\nDistillation\nRealtime API\nBatch API\nASSISTANTS\nOverview\nQuickstart\nDeep dive\nTools\nWhat's new?\nMigration guide\nCHATGPT\nActions\nIntroduction\nGetting started\nActions library\nAuthentication\nProduction\nData retrieval\nSending files\nPolicies\nRelease notes\nBEST PRACTICES\nPrompt engineering\nProduction best practices\nSafety best practices\nPrompt Caching\nModel selection\nLatency optimization\nAccuracy optimization\nAdvanced usage\nRESOURCES\nLibraries\nPrompt examples\nRate limits\nPrompt generation\nError codes\nDeprecations\nCookbook\nForum\nHelp\nGPT Actions library\nBuild and integrate GPT Actions for common applications.\nPurpose\n\nWhile GPT Actions should be significantly less work for an API developer to set up than an entire application using those APIs from scratch, there‚Äôs still some set up required to get GPT Actions up and running. A Library of GPT Actions is meant to provide guidance for building GPT Actions on common applications.\n\nGetting started\n\nIf you‚Äôve never built an action before, start by reading the getting started guide first to understand better how actions work.\n\nGenerally, this guide is meant for people with familiarity and comfort with calling API calls. For debugging help, try to explain your issues to ChatGPT - and include screenshots.\n\nHow to access\n\nThe OpenAI Cookbook has a directory of 3rd party applications and middleware application.\n\n3rd party Actions cookbook\n\nGPT Actions can integrate with HTTP services directly. GPT Actions leveraging SaaS API directly will authenticate and request resources directly from SaaS providers, such as Google Drive or Snowflake.\n\nMiddleware Actions cookbook\n\nGPT Actions can benefit from having a middleware. It allows pre-processing, data formatting, data filtering or even connection to endpoints not exposed through HTTP (e.g: databases). Multiple middleware cookbooks are available describing an example implementation path, such as Azure, GCP and AWS.\n\nGive us feedback\n\nAre there integrations that you‚Äôd like us to prioritize? Are there errors in our integrations? File a PR or issue on the cookbook page's github, and we‚Äôll take a look.\n\nContribute to our library\n\nIf you‚Äôre interested in contributing to our library, please follow the below guidelines, then submit a PR in github for us to review. In general, follow the template similar to this example GPT Action.\n\nGuidelines - include the following sections:\n\nApplication Information - describe the 3rd party application, and include a link to app website and API docs\nCustom GPT Instructions - include the exact instructions to be included in a Custom GPT\nOpenAPI Schema - include the exact OpenAPI schema to be included in the GPT Action\nAuthentication Instructions - for OAuth, include the exact set of items (authorization URL, token URL, scope, etc.); also include instructions on how to write the callback URL in the application (as well as any other steps)\nFAQ and Troubleshooting - what are common pitfalls that users may encounter? Write them here and workarounds\nDisclaimers\n\nThis action library is meant to be a guide for interacting with 3rd parties that OpenAI have no control over. These 3rd parties may change their API settings or configurations, and OpenAI cannot guarantee these Actions will work in perpetuity. Please see them as a starting point.\n\nThis guide is meant for developers and people with comfort writing API calls. Non-technical users will likely find these steps challenging.\n\nWas this page useful?\n\nEnd of content from https://platform.openai.com/docs/actions/actions-library"
    ],
    [
      "page:1732198204002",
      "Fetched content from https://platform.openai.com/docs/actions/getting-started on 2024-11-21 14:10:04\n\nF\nf19n.com\n/\nNeverendingjoke\nPlayground\nDashboard\nDocs\nAPI\nSearch\n‚åò\nK\nGET STARTED\nOverview\nQuickstart\nModels\nChangelog\nTerms and policies\nCAPABILITIES\nText generation\nImage generation\nVision\nAudio generation\nText to speech\nSpeech to text\nEmbeddings\nModeration\nReasoning\nGUIDES\nFunction calling\nStructured Outputs\nPredicted Outputs\nEvaluations\nFine-tuning\nDistillation\nRealtime API\nBatch API\nASSISTANTS\nOverview\nQuickstart\nDeep dive\nTools\nWhat's new?\nMigration guide\nCHATGPT\nActions\nIntroduction\nGetting started\nActions library\nAuthentication\nProduction\nData retrieval\nSending files\nPolicies\nRelease notes\nBEST PRACTICES\nPrompt engineering\nProduction best practices\nSafety best practices\nPrompt Caching\nModel selection\nLatency optimization\nAccuracy optimization\nAdvanced usage\nRESOURCES\nLibraries\nPrompt examples\nRate limits\nPrompt generation\nError codes\nDeprecations\nCookbook\nForum\nHelp\nGetting started with GPT Actions\nSet up and test GPT Actions from scratch.\nWeather.gov example\n\nThe NSW (National Weather Service) maintains a public API that users can query to receive a weather forecast for any lat-long point. To retrieve a forecast, there‚Äôs 2 steps:\n\nA user provides a lat-long to the api.weather.gov/points API and receives back a WFO (weather forecast office), grid-X, and grid-Y coordinates\nThose 3 elements feed into the api.weather.gov/forecast API to retrieve a forecast for that coordinate\n\nFor the purpose of this exercise, let‚Äôs build a Custom GPT where a user writes a city, landmark, or lat-long coordinates, and the Custom GPT answers questions about a weather forecast in that location.\n\nStep 1: Write and test Open API schema (using Actions GPT)\n\nA GPT Action requires an Open API schema to describe the parameters of the API call, which is a standard for describing APIs.\n\nOpenAI released a public Actions GPT to help developers write this schema. For example, go to the Actions GPT and ask: ‚ÄúGo to https://www.weather.gov/documentation/services-web-api and read the documentation on that page. Build an Open API Schema for the /points/{latitude},{longitude} and /gridpoints/{office}/{gridX},{gridY}/forecast‚Äù API calls‚Äù\n\nDEEP DIVE\nSee Full Open API Schema\n\nChatGPT uses the info at the top (including the description in particular) to determine if this action is relevant for the user query.\n\n1\n2\n3\n4\n\ninfo:\n  title: NWS Weather API\n  description: Access to weather data including forecasts, alerts, and observations.\n  version: 1.0.0\n\nThen the parameters below further define each part of the schema. For example, we're informing ChatGPT that the office parameter refers to the Weather Forecast Office (WFO).\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n/gridpoints/{office}/{gridX},{gridY}/forecast:\n  get:\n    operationId: getGridpointForecast\n    summary: Get forecast for a given grid point\n    parameters:\n      - name: office\n        in: path\n        required: true\n        schema:\n          type: string\n        description: Weather Forecast Office ID\n\nKey: Pay special attention to the schema names and descriptions that you use in this Open API schema. ChatGPT uses those names and descriptions to understand (a) which API action should be called and (b) which parameter should be used. If a field is restricted to only certain values, you can also provide an \"enum\" with descriptive category names.\n\nWhile you can just try the Open API schema directly in a GPT Action, debugging directly in ChatGPT can be a challenge. We recommend using a 3rd party service, like Postman, to test that your API call is working properly. Postman is free to sign up, verbose in its error-handling, and comprehensive in its authentication options. It even gives you the option of importing Open API schemas directly (see below).\n\nStep 2: Identify authentication requirements\n\nThis Weather 3rd party service does not require authentication, so you can skip that step for this Custom GPT. For other GPT Actions that do require authentication, there are 2 options: API Key or OAuth. Asking ChatGPT can help you get started for most common applications. For example, if I needed to use OAuth to authenticate to Google Cloud, I can provide a screenshot and ask for details: ‚ÄúI‚Äôm building a connection to Google Cloud via OAuth. Please provide instructions for how to fill out each of these boxes.‚Äù\n\nOften, ChatGPT provides the correct directions on all 5 elements. Once you have those basics ready, try testing and debugging the authentication in Postman or another similar service. If you encounter an error, provide the error to ChatGPT, and it can usually help you debug from there.\n\nStep 3: Create the GPT Action and test\n\nNow is the time to create your Custom GPT. If you've never created a Custom GPT before, start at our Creating a GPT guide.\n\nProvide a name, description, and image to describe your Custom GPT\nGo to the Action section and paste in your Open API schema. Take a note of the Action names and json parameters when writing your instructions.\nAdd in your authentication settings\nGo back to the main page and add in instructions\nDEEP DIVE\nGuidance on Writing Instructions\nTest the GPT Action\n\nNext to each action, you'll see a Test button. Click on that for each action. In the test, you can see the detailed input and output of each API call.\n\nIf your API call is working in a 3rd party tool like Postman and not in ChatGPT, there are a few possible culprits:\n\nThe parameters in ChatGPT are wrong or missing\nAn authentication issue in ChatGPT\nYour instructions are incomplete or unclear\nThe descriptions in the Open API schema are unclear\nStep 4: Set up callback URL in the 3rd party app\n\nIf your GPT Action uses OAuth Authentication, you‚Äôll need to set up the callback URL in your 3rd party application. Once you set up a GPT Action with OAuth, ChatGPT provides you with a callback URL (this will update any time you update one of the OAuth parameters). Copy that callback URL and add it to the appropriate place in your application.\n\nStep 5: Evaluate the Custom GPT\n\nEven though you tested the GPT Action in the step above, you still need to evaluate if the Instructions and GPT Action function in the way users expect. Try to come up with at least 5-10 representative questions (the more, the better) of an ‚Äúevaluation set‚Äù of questions to ask your Custom GPT.\n\nKey: Test that the Custom GPT handles each one of your questions as you expect.\n\nAn example question: ‚ÄúWhat should I pack for a trip to the White House this weekend?‚Äù tests the Custom GPT‚Äôs ability to: (1) convert a landmark to a lat-long, (2) run both GPT Actions, and (3) answer the user‚Äôs question.\n\n \nCommon Debugging Steps\n\nChallenge: The GPT Action is calling the wrong API call (or not calling it at all)\n\nSolution: Make sure the descriptions of the Actions are clear - and refer to the Action names in your Custom GPT Instructions\n\nChallenge: The GPT Action is calling the right API call but not using the parameters correctly\n\nSolution: Add or modify the descriptions of the parameters in the GPT Action\n\nChallenge: The Custom GPT is not working but I am not getting a clear error\n\nSolution: Make sure to test the Action - there are more robust logs in the test window. If that is still unclear, use Postman or another 3rd party service to better diagnose.\n\nChallenge: The Custom GPT is giving an authentication error\n\nSolution: Make sure your callback URL is set up correctly. Try testing the exact same authentication settings in Postman or another 3rd party service\n\nChallenge: The Custom GPT cannot handle more difficult / ambiguous questions\n\nSolution: Try to prompt engineer your instructions in the Custom GPT. See examples in our prompt engineering guide\n\nThis concludes the guide to building a Custom GPT. Good luck building and leveraging the OpenAI developer forum if you have additional questions.\n\nWas this page useful?\n\nEnd of content from https://platform.openai.com/docs/actions/getting-started"
    ],
    [
      "page:1732198467785",
      "Fetched content from https://help.openai.com/en/articles/8554397-creating-a-gpt on 2024-11-21 14:14:27\n\nSkip to main content\nEnglish\nEnglish\nAll Collections\nChatGPT\nGPTs\nBuilding GPTs\nCreating a GPT\nCreating a GPT\n\nHow to create a GPT\n\nUpdated over a month ago\nTable of contents\n\nCreating a GPT is only available to paid users and is currently powered by GPT-4o.\n\n \n\nGPTs are custom versions of ChatGPT that users can tailor for specific tasks or topics by combining instructions, knowledge, and capabilities. They can be as simple or as complex as needed, addressing anything from language learning to technical support. Plus, Team, and Enterprise users can start creating GPTs at chatgpt.com/create.\n\n \n\nHere‚Äôs how to create a GPT:\n\nHead to https://chatgpt.com/gpts/editor (or select your name and then ‚ÄúMy GPTs‚Äù)\n\nSelect ‚ÄúCreate a GPT‚Äù\n\nIn the Create tab, you can message the GPT Builder to help you build a new GPT. You can say something like, \"Make a creative who helps generate visuals for new products\" or \"Make a software engineer who helps format my code.\"\n\nTo name and set the description of your GPT, head to the Configure tab. Here, you will also be able to select the actions you would like your GPT to take, like browsing the web or creating images.\n\nWhen you‚Äôre ready to publish your GPT, select ‚ÄúPublish‚Äù and share it with other people if you‚Äôd like. \n\nNow you‚Äôve created a GPT!\n\n \n\nAdvanced Settings\n\nIn the GPT Editor, you can configure more detailed settings for your GPT. \n\n \n\nAt the top, there are two tabs labeled Create and Configure. Create allows you to message the GPT Builder to help you build a new GPT. If you would like to provide more detailed instructions, you can set them in the Configure tab.\n\n \n\nSettings in the Configure tab:\n\nAdding an image: You can ask the GPT Builder to create an image for your GPT or you can upload your own under the Configure tab. \n\nAdditional Instructions: Here you can provide detailed instructions or guidelines on how the GPT should behave, its functionalities, and any particular behaviors to avoid.\n\nPrompt Starters: These are examples of prompts for the user to start the conversation. \n\nKnowledge: This allows you to provide additional context for your GPT to reference. Please note that content from the files that are uploaded could be included in the output.\n\nNew Capabilities: Enabling Web Browsing, DALL¬∑E Image Generation, and Advanced Data Analysis, will allow the GPT to perform additional functionality. \n\nCustom Actions: You can make third-party APIs available to your GPT by providing details about the endpoints, parameters, and a description about how the model should use it. Actions for GPTs can also be imported from an OpenAPI schema. So if you‚Äôve already built a plugin, you will be able to use your existing plugin manifests to define actions for your GPT.\n‚Äã\n\nManaging your GPTs\n\nAs an owner of your ChatGPT workspace, you'll be able to check on the settings and performance of your GPTs. Within your account settings at the bottom left of your screen, click on \"Manage workspace\" to navigate to your workspace settings.\n\n \n\nFrom here, click \"GPTs\" to see all of your GPTs published. Scroll down to the table view of your GPTs. The table view allows you to edit specific ownership and access of each individual GPT. You can use the filter at the top right of the table to further narrow down GPTs by capabilities and access.\n\n \n\nUnderstanding your GPT metrics\n\nIn this same view within your GPTs list, you can see how much your GPT has been used. The \"Chats\" column shows the total number of chats initiated within the GPT since its creation.\n\n \n\nIf your number is 10+ or 100+, that means the total number of chats is between 10-20 or 100-200.\n\n \n\nFAQ: \n\nQ: How many files can I upload to a GPT? \n\nA: We allow up to 20 files to be uploaded to a custom GPT.\n\n \n\nRelated Articles\nHow can I access GPT-4, GPT-4 Turbo, GPT-4o, and GPT-4o mini?\nGPTs Data Privacy FAQs\nGPTs (ChatGPT Enterprise version)\nGPTs vs Assistants\nBuilding and publishing a GPT\nDid this answer your question?\nüòûüòêüòÉ\nChatGPTAPIDALL¬∑EService Status\n\nEnd of content from https://help.openai.com/en/articles/8554397-creating-a-gpt"
    ],
    [
      "page:1732198470829",
      "Fetched content from https://help.openai.com/en/articles/8843948-knowledge-in-gpts on 2024-11-21 14:14:30\n\nSkip to main content\nEnglish\nEnglish\nAll Collections\nChatGPT\nGPTs\nBuilding GPTs\nKnowledge in GPTs\nKnowledge in GPTs\n\nHere is what you need to know about the GPT knowledge feature\n\nUpdated over 9 months ago\nTable of contents\nWhat is Knowledge?\n\nUsing the knowledge feature in a GPT, builders can upload files containing additional context. GPTs then use a variety of methods to access this data in response to user prompts.\n\n \n\nHow does Knowledge work?\n\nYou can use the GPT editor to attach up to 20 files to a GPT. Each file can be up to 512 MB in size and can contain 2,000,000 tokens. You can include files containing images, but only the text is currently processed. When you upload a file, the GPT breaks the text up into chunks, creates embeddings (a mathematical way of representing text), and stores them for later use.\n\n \n\nWhen a user interacts with your GPT,  the GPT can access the uploaded files to get additional context to augment the user‚Äôs query. The GPT chooses one of the following methods based on the requirements of the user‚Äôs prompt:\n\nSemantic search - Returns relevant text chunks as described above.\n\nPreferred when responding to ‚ÄúQ&A‚Äù style prompts, where a specific portion of the source document is required.\n\nDocument review - Entire short documents and/or relevant excerpts of larger documents are returned and included along with the prompt as additional context.\n\nPreferred when responding to summarization or translation prompts, where the entire source document is required.\n\nWhen to use Knowledge\n\nCurrently, the only way to manage the files attached to a GPT is using the GPT Builder UI. This means it is best for applications where context changes infrequently (employee handbooks, policy documents, school curricula, etc).\n\n \n\nTips for getting the most out of Knowledge\n\nThe file parser we use to extract text from documents work best with simple formatting. A single column of text is best. The parser can struggle with multi-column PDFs, and won‚Äôt understand the nuance conveyed by the relative positions of text on a PowerPoint slide.\n\nUsing Instructions in the GPT editor, you can encourage the GPT to rely on Knowledge first before searching the internet.\n\nBy default, GPTs will avoid revealing the names of uploaded files. If you want GPTs to ‚Äúcite their sources,‚Äù indicate that in the Instructions.\n\nRelated Articles\nHow can I access GPT-4, GPT-4 Turbo, GPT-4o, and GPT-4o mini?\nCreating a GPT\nGPT-4 Turbo in the OpenAI API\nGPT Builder\nRetrieval Augmented Generation (RAG) and Semantic Search for GPTs\nDid this answer your question?\nüòûüòêüòÉ\nChatGPTAPIDALL¬∑EService Status\n\nEnd of content from https://help.openai.com/en/articles/8843948-knowledge-in-gpts"
    ],
    [
      "page:1732198484906",
      "Fetched content from https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts on 2024-11-21 14:14:44\n\nSkip to main content\nEnglish\nEnglish\nAll Collections\nChatGPT\nGPTs\nBuilding GPTs\nRetrieval Augmented Generation (RAG) and Semantic Search for GPTs\nRetrieval Augmented Generation (RAG) and Semantic Search for GPTs\n\nLearn about RAG and how it is useful to GPT builders\n\nUpdated over 9 months ago\nTable of contents\nWhat is Retrieval Augmented Generation (RAG), and why is it valuable for GPT builders?\n\nRAG is the process of retrieving relevant contextual information from a data source and passing that information to a large language model alongside the user‚Äôs prompt. This information is used to improve the model‚Äôs output (generated text or images) by augmenting the model‚Äôs base knowledge. \n\n \n\nBasic RAG workflow\n\n \n\nRAG is valuable for use-cases where the model needs knowledge which is not included in the information the model has learned from. For example, let‚Äôs say you are building a GPT to help your support team answer customer inquiries. GPT-4 is able to reason about customer problems using its base knowledge, but it cannot know the latest facts about your specific product or service. You can get much better results by giving a GPT access to your ticketing system, so that it can retrieve past tickets pertaining to similar issues and use that context to generate more relevant answers. When you use the knowledge retrieval feature in a GPT, RAG is being performed for you automatically.\n\n \n\nWhat is Semantic Search?\n\nSemantic search goes beyond keyword search (which relies on the occurrence of specific index words in the search input) to find contextually relevant data based on the conceptual similarity of the input string. \n\nData source\n\n\t\n\nSearch method\n\n\n\n\nDocument management systems (Google Drive, Sharepoint, etc.)\n\n\t\n\nKeyword search, custom query string\n\n\n\n\nRelational databases (Postgres, MySQL, etc.)\n\n\t\n\nSQL query\n\n\n\n\nVector databases\n\n\t\n\nSemantic search query\n\nAs a result, it has been a good choice for providing more context to models like GPT-4 (since queries are likely to be heavily context dependent). Semantic search uses a vector database, which stores text chunks (derived from some documents) and their vectors (mathematical representations of the text). When you query a vector database, the search input (in vector form) is compared to all of the stored vectors, and the most similar text chunks are returned.\n\n \n\nExample of semantic search\n\nLet‚Äôs say that you are building a customer support chatbot. If you want to populate a vector database with articles from a knowledge base, you might:\n\nBreak each of the articles up into chunks\n\nThis could be at the sentence, paragraph, or page level. Different chunking strategies will yield different results.\n\nUse the OpenAI Embedding API to process those chunks and return embeddings (i.e. mathematical representations of the nature of the chunk in vector space)\n\nFor example: [ -0.006929283495992422,-0.005336422007530928, ‚Ä¶ -4.547132266452536e-05, -0.024047505110502243]\n\nStore the chunks and their embeddings in the database\n\nWhen a user asks the chatbot a question, a semantic search is performed:\n\nUser submits a query like ‚ÄúHow can I use the OpenAI API?‚Äù\n\nUse the OpenAI Embedding API to produce a vector representation of the query string\n\nSubmit that vector to the search endpoint associated with my vector db\n\nGet back one or more text chunks which are similar to my query\n\nThe chatbot application then submits the text chunks along with the initial user prompt to the OpenAI Chat Completions API to get a response.\n\n \n\nFor GPT builders, you can leverage semantic search out of the box by uploading files and enabling knowledge retrieval in your GPT.\n\nRelated Articles\nHow can I access GPT-4, GPT-4 Turbo, GPT-4o, and GPT-4o mini?\nGPT-4 Turbo in the OpenAI API\nGPTs vs Assistants\nKnowledge in GPTs\nChatGPT Capabilities Overview\nDid this answer your question?\nüòûüòêüòÉ\nChatGPTAPIDALL¬∑EService Status\n\nEnd of content from https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts"
    ],
    [
      "page:1732198492433",
      "Fetched content from https://help.openai.com/en/articles/9358033-key-guidelines-for-writing-instructions-for-custom-gpts on 2024-11-21 14:14:52\n\nSkip to main content\nEnglish\nEnglish\nAll Collections\nChatGPT\nGPTs\nKey Guidelines for Writing Instructions for Custom GPTs\nKey Guidelines for Writing Instructions for Custom GPTs\nUpdated over 6 months ago\nTable of contents\n\nAs you transition to writing Custom GPTs, implementing effective prompt engineering practices within your instructions is crucial to ensure your GPTs perform reliably and accurately. Here‚Äôs a concise guide to help you navigate smoothly with your Custom GPTs.\n\n \n\nEnhancing Instructions\n\nSimplify Complex Instructions:\n\nBreak down multi-step instructions into simpler, more manageable steps to ensure the model can follow them accurately.\n\nUse ‚Äútrigger/instruction pairs‚Äù, separated by delimiters to improve reliability in following steps without merging or skipping them.\n\nThese look like the following:\n\n \n\nTrigger: User submits information\nInstruction: Analyze information for themes\n\n \n\nTrigger: Themes analyzed\nInstruction: Leverage themes analyzed to provide summary\n in bullet point form of the recommendations you‚Äôd give\n\n \n\nStructure for Clarity:\n\nBreak down second-level instructions into separate steps for better execution.\n\nUse delimiters between instruction sets and for call-outs of few-shot examples to enhance clarity.\n\nPromote Attention to Detail:\n\nIncorporate ‚Äútake your time,‚Äù ‚Äútake a deep breath,‚Äù and ‚Äúcheck your work‚Äù techniques to encourage the model to be thorough.\n\nUse ‚Äústrengthening language‚Äù to highlight critical parts of the instructions, ensuring they are not overlooked.\n\nAvoid Negative Instructions:\n\nFrame instructions positively to improve adherence and avoid confusion.\n\nGranular Steps:\n\nBreak down steps as granularly as possible, especially when multiple actions are required within a single step.\n\nConsistency and Clarity:\n\nExplicitly define terms and definitions you are expecting using few-shot prompting (e.g., acceptable vs. unacceptable changes) to improve consistency in evaluations.\n\nClarify any relevant classifications with few-shot examples to reduce variability in output.\n\nSpecial Care with Tools and Actions\n\nLeveraging Knowledge Files:\n\nProvide explicit instructions for using knowledge files, including specifying file names. \n\nInstruct the model to slow down and analyze the entire file to ensure comprehensive utilization.\n\nSpecificity in Prompts for Knowledge Extraction:\n\nAdd specificity in prompts, particularly when extracting critical information like dates or financial information. Give specific examples through ‚Äúfew shot prompting‚Äù.\n\nEncourage the model to thoroughly check its work and take its time when retrieving specific data from files.\n\nExamples of Good Output:\n\nProvide examples of what good output looks like concerning knowledge and custom actions.\n\nReferencing Actions:\n\nAlways refer to actions by name and domain to enhance clarity.\n\nProvide ‚Äúfew-shot prompting‚Äù examples with API calls where needed to ensure correct action is called.\n\nUse delimiters for different action steps to ensure the correct actions are called.\n\nExplicit Tool Use Instructions:\n\nProvide explicit instructions to use tools such as Browse, Knowledge, and Custom Actions throughout the instructions. \n\nBy following these guidelines, you can optimize the performance of your custom GPTs, ensuring reliable and accurate outputs.\n\nRelated Articles\nCreating a GPT\nGPT-4 Turbo in the OpenAI API\nGPT Builder\nKnowledge in GPTs\nPrompt engineering best practices for ChatGPT\nDid this answer your question?\nüòûüòêüòÉ\nChatGPTAPIDALL¬∑EService Status\n\nEnd of content from https://help.openai.com/en/articles/9358033-key-guidelines-for-writing-instructions-for-custom-gpts"
    ]
  ],
  "selectionOrder": [
    "page:1732198150881",
    "page:1732198160957",
    "page:1732198169327",
    "page:1732198204002",
    "page:1732198467785",
    "page:1732198470829",
    "page:1732198484906",
    "page:1732198492433"
  ]
}